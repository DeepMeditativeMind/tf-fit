{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_learner.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_YLAW2teP0KC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu90/torch_nightly.html\n",
        "!pip install git+https://github.com/Pendar2/fastai\n",
        "!wget www.pendar2.com/cifar10.zip\n",
        "!wget www.pendar2.com/mnist.zip\n",
        "!unzip cifar10.zip > zip-log\n",
        "!unzip mnist.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gPqGmZDEPYhm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7WI_uoiqlcIn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tf_fit import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iU9kDQ3MPYiN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ]
    },
    {
      "metadata": {
        "id": "zp5TZ0OMPYiN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATA_PATH = Path('./')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rt8G8H_4PYiP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt_fn = tf.train.AdamOptimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lPVC8tPvPYiR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_fn = tf.losses.sparse_softmax_cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8LHmlYUPYiU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def categorical_accuracy_fastai(y_pred, y_true):\n",
        "    y_pred = tf.constant(y_pred.numpy())\n",
        "    y_true = tf.constant(y_true.numpy())\n",
        "    return tf.keras.backend.mean(tf.keras.backend.equal(y_true, tf.keras.backend.argmax(y_pred, axis=-1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TZiBOhoWPYiW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metrics = [categorical_accuracy_fastai]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9t5SHjDwPYiY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MNIST with tf.keras.Model"
      ]
    },
    {
      "metadata": {
        "id": "xy3Kzo_zPYiY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gzip, pickle\n",
        "MNIST_PATH = DATA_PATH/'mnist'\n",
        "\n",
        "with gzip.open(MNIST_PATH/'mnist.pkl.gz', 'rb') as f:\n",
        "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "\n",
        "x_train,y_train,x_valid,y_valid = map(torch.tensor, (x_train,y_train,x_valid,y_valid))\n",
        "train_ds = TensorDataset(x_train, y_train)\n",
        "valid_ds = TensorDataset(x_valid, y_valid)\n",
        "train_dl = DataLoader(train_ds, 64)\n",
        "valid_dl = DataLoader(valid_ds, 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d81v0k3qPYia",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = DataBunch(train_dl, valid_dl, path=MNIST_PATH, device=torch.device('cpu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oryCjfdJPYic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Mnist_CNN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(16, kernel_size=3, strides=(2,2), padding='same')\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization(axis=-1)\n",
        "        self.conv2 = tf.keras.layers.Conv2D(16, kernel_size=3, strides=(2,2), padding='same')\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization(axis=-1)\n",
        "        self.conv3 = tf.keras.layers.Conv2D(10, kernel_size=3, strides=(2,2), padding='same')\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization(axis=-1)\n",
        "    def call(self, xb):\n",
        "        xb = tf.reshape(xb, (-1, 1, 28, 28))\n",
        "        xb = tf.nn.relu(self.bn1(self.conv1(xb)))\n",
        "        xb = tf.nn.relu(self.bn2(self.conv2(xb)))\n",
        "        xb = tf.nn.relu(self.bn3(self.conv3(xb)))\n",
        "        xb = tf.nn.pool(xb, (4,4), 'AVG', 'VALID', data_format=\"NCHW\")\n",
        "        xb = tf.reshape(xb, (-1, 10))\n",
        "        return xb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w68rISbqPYih",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Mnist_CNN()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1GDMSKgtPYik",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = TfLearner(data, model, opt_fn, loss_fn, metrics=metrics, true_wd=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "raiVcblJPYil",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IZmV9hTNGR7H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(1, lr=.1, wd=0.4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GVUpFoBFPYiq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(3, max_lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JCmV71rAPYir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.recorder.plot_lr(show_moms=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xIb_UKBJPYit",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.recorder.plot_losses()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bwwTsEk2W_MK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.recorder.plot_metrics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5E0cIZiNPYiu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save(\"test-mnist\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LGj6zkkkPYix",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load(\"test-mnist\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QJ07YBIJPYiy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CIFAR with Keras functional API"
      ]
    },
    {
      "metadata": {
        "id": "AcinEP5YPYiy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai.vision import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ooqx_TkgPYi0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CIFAR_PATH = DATA_PATH/\"cifar10\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mv2kiw0APYi2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds_tfms = ([pad(padding=4), crop(size=32, row_pct=(0,1), col_pct=(0,1)), flip_lr(p=0.5)], [])\n",
        "data = ImageDataBunch.from_folder(CIFAR_PATH, valid='test', ds_tfms=ds_tfms, tfms=cifar_norm, bs=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EwLPgNmfPYi3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xb, yb = next(iter(data.train_dl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MO1jx5nCPYi5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xb.shape, yb.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EegCFIQ1PYi6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from https://github.com/raghakot/keras-resnet\n",
        "import six\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "def _bn_relu(input):\n",
        "    \"\"\"Helper to build a BN -> relu block\n",
        "    \"\"\"\n",
        "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
        "    return Activation(\"relu\")(norm)\n",
        "\n",
        "\n",
        "def _conv_bn_relu(**conv_params):\n",
        "    \"\"\"Helper to build a conv -> BN -> relu block\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(input)\n",
        "        return _bn_relu(conv)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _bn_relu_conv(**conv_params):\n",
        "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
        "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        activation = _bn_relu(input)\n",
        "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(activation)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _shortcut(input, residual):\n",
        "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
        "    \"\"\"\n",
        "    # Expand channels of shortcut to match residual.\n",
        "    # Stride appropriately to match residual (width, height)\n",
        "    # Should be int if network architecture is correctly configured.\n",
        "    input_shape = K.int_shape(input)\n",
        "    residual_shape = K.int_shape(residual)\n",
        "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
        "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
        "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
        "\n",
        "    shortcut = input\n",
        "    # 1 X 1 conv if shape is different. Else identity.\n",
        "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
        "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
        "                          kernel_size=(1, 1),\n",
        "                          strides=(stride_width, stride_height),\n",
        "                          padding=\"valid\",\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.0001))(input)\n",
        "\n",
        "    return add([shortcut, residual])\n",
        "\n",
        "\n",
        "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
        "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "        for i in range(repetitions):\n",
        "            init_strides = (1, 1)\n",
        "            if i == 0 and not is_first_layer:\n",
        "                init_strides = (2, 2)\n",
        "            input = block_function(filters=filters, init_strides=init_strides,\n",
        "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
        "        return input\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
        "                           strides=init_strides,\n",
        "                           padding=\"same\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=l2(1e-4))(input)\n",
        "        else:\n",
        "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
        "                                  strides=init_strides)(input)\n",
        "\n",
        "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    Returns:\n",
        "        A final conv layer of filters * 4\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
        "                              strides=init_strides,\n",
        "                              padding=\"same\",\n",
        "                              kernel_initializer=\"he_normal\",\n",
        "                              kernel_regularizer=l2(1e-4))(input)\n",
        "        else:\n",
        "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
        "                                     strides=init_strides)(input)\n",
        "\n",
        "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
        "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _get_block(identifier):\n",
        "    if isinstance(identifier, six.string_types):\n",
        "        res = globals().get(identifier)\n",
        "        if not res:\n",
        "            raise ValueError('Invalid {}'.format(identifier))\n",
        "        return res\n",
        "    return identifier\n",
        "\n",
        "CHANNEL_AXIS = 1\n",
        "ROW_AXIS = 2\n",
        "COL_AXIS = 3\n",
        "class ResnetBuilder(object):\n",
        "    @staticmethod\n",
        "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
        "        \"\"\"Builds a custom ResNet like architecture.\n",
        "        Args:\n",
        "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
        "            num_outputs: The number of outputs at final softmax layer\n",
        "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
        "                The original paper used basic_block for layers < 50\n",
        "            repetitions: Number of repetitions of various block units.\n",
        "                At each block unit, the number of filters are doubled and the input size is halved\n",
        "        Returns:\n",
        "            The keras `Model`.\n",
        "        \"\"\"\n",
        "        if len(input_shape) != 3:\n",
        "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
        "\n",
        "\n",
        "        # Load function from str if needed.\n",
        "        block_fn = _get_block(block_fn)\n",
        "\n",
        "        input = Input(shape=input_shape)\n",
        "        #x = Permute((3,2,1))(input)\n",
        "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
        "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
        "\n",
        "        block = pool1\n",
        "        filters = 64\n",
        "        for i, r in enumerate(repetitions):\n",
        "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
        "            filters *= 2\n",
        "\n",
        "        # Last activation\n",
        "        block = _bn_relu(block)\n",
        "\n",
        "        # Classifier block\n",
        "        block_shape = K.int_shape(block)\n",
        "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
        "                                 strides=(1, 1))(block)\n",
        "        flatten1 = Flatten()(pool2)\n",
        "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\")(flatten1)\n",
        "\n",
        "        model = Model(inputs=input, outputs=dense)\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_18(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_34(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_50(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_101(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_152(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BnASjR_zPYi7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "K.image_data_format()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qQzHiKdXPYi9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resnet = ResnetBuilder.build_resnet_50((3, 32 ,32), 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wu5o9qFsPYi_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = TfLearner(data, resnet, opt_fn, loss_fn, metrics=metrics, bn_wd=True, train_bn=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jQaU02JgU4i5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qlf4m4NVm2U8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(1, wd=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PMR0vIH8Vb2w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "default_wd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PQagy_RYhwp2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "learn.fit_one_cycle(30, 3e-3, wd=0.4, div_factor=10, pct_start=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_JnMnvCsuqRu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.recorder.plot(_metrics())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B9dBy18Ac-mg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Other"
      ]
    }
  ]
}